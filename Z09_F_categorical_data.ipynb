{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Eyi1btb7dBZa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS_qc5BsdBZe"
      },
      "source": [
        "# Categorical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8aXJpOogdBZl",
        "outputId": "4e0a5260-2915-4efe-a007-f42fd55d4530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           workclass  age   education  education-num          occupation  \\\n",
              "0          State-gov   39   Bachelors            NaN        Adm-clerical   \n",
              "1   Self-emp-not-inc   50   Bachelors           13.0     Exec-managerial   \n",
              "2            Private   38     HS-grad            9.0   Handlers-cleaners   \n",
              "3            Private   53        11th            7.0   Handlers-cleaners   \n",
              "4            Private   28   Bachelors           13.0      Prof-specialty   \n",
              "\n",
              "   capital-gain   gender  hours-per-week  income  \n",
              "0          2174     Male              40   <=50K  \n",
              "1             0     Male              13   <=50K  \n",
              "2             0     Male              40   <=50K  \n",
              "3             0     Male              40   <=50K  \n",
              "4             0   Female              40   <=50K  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa94ad2c-5d7b-47b7-962f-b2d6e44382b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>workclass</th>\n",
              "      <th>age</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>occupation</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>gender</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>State-gov</td>\n",
              "      <td>39</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>2174</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>50</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>0</td>\n",
              "      <td>Male</td>\n",
              "      <td>13</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Private</td>\n",
              "      <td>38</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>0</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Private</td>\n",
              "      <td>53</td>\n",
              "      <td>11th</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>0</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Private</td>\n",
              "      <td>28</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>0</td>\n",
              "      <td>Female</td>\n",
              "      <td>40</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa94ad2c-5d7b-47b7-962f-b2d6e44382b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa94ad2c-5d7b-47b7-962f-b2d6e44382b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa94ad2c-5d7b-47b7-962f-b2d6e44382b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# The file has no headers naming the columns, so we pass header=None\n",
        "# and provide the column names explicitly in \"names\"\n",
        "data = pd.read_csv(\n",
        "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", na_values=[\" ?\"], \n",
        "    header=None, index_col=False,\n",
        "    names=['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        "    'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
        "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
        "    'income'])\n",
        "# For illustration purposes, we only select some of the columns\n",
        "data = data[['workclass', 'age', 'education', 'education-num', 'occupation', 'capital-gain','gender', 'hours-per-week',  'income']]\n",
        "# IPython.display allows nice output formatting within the Jupyter notebook\n",
        "# add some none\n",
        "data['education-num'][0]=None\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JI_g4m1OdBZn"
      },
      "outputs": [],
      "source": [
        "data = data[1:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SjFcyc4ndBZr",
        "outputId": "658ffcd4-0d12-4d7e-9c7b-c35e1ab142bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "workclass         62\n",
              "age                0\n",
              "education          0\n",
              "education-num      0\n",
              "occupation        62\n",
              "capital-gain       0\n",
              "gender             0\n",
              "hours-per-week     0\n",
              "income             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN9m2TQBdBZs"
      },
      "source": [
        "Teraz rzućmy okiem na wszystkie atrybuty kategoryczne:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zz_jJmHhdBZt",
        "outputId": "76640d99-e2be-4f77-e21d-3b7a3467956f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " Private             698\n",
              " Self-emp-not-inc     81\n",
              " Local-gov            68\n",
              " State-gov            36\n",
              " Self-emp-inc         33\n",
              " Federal-gov          21\n",
              "Name: workclass, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data[\"workclass\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qDk03k3cdBZu",
        "outputId": "08c18419-b186-4b15-c274-abd0f2f838a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " HS-grad         321\n",
              " Some-college    225\n",
              " Bachelors       165\n",
              " Masters          54\n",
              " Assoc-voc        48\n",
              " 11th             46\n",
              " Assoc-acdm       35\n",
              " 10th             21\n",
              " 9th              16\n",
              " 7th-8th          15\n",
              " Doctorate        14\n",
              " 5th-6th          11\n",
              " Prof-school      10\n",
              " 12th              9\n",
              " 1st-4th           7\n",
              " Preschool         2\n",
              "Name: education, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data[\"education\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jQe2joTvdBZw",
        "outputId": "11e9f9da-0f8a-4470-c857-2f8d128dc808",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " Male      670\n",
              " Female    329\n",
              "Name: gender, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data[\"gender\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AI_MXVnedBZz",
        "outputId": "89113054-ccf2-4db5-964c-9420541188c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " Craft-repair         126\n",
              " Exec-managerial      124\n",
              " Prof-specialty       124\n",
              " Sales                112\n",
              " Other-service        107\n",
              " Adm-clerical          93\n",
              " Machine-op-inspct     61\n",
              " Transport-moving      52\n",
              " Tech-support          44\n",
              " Handlers-cleaners     43\n",
              " Farming-fishing       31\n",
              " Protective-serv       16\n",
              " Priv-house-serv        3\n",
              " Armed-Forces           1\n",
              "Name: occupation, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data[\"occupation\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WiVIypVdBZ0"
      },
      "source": [
        "Sprawdźmy, czy etykiety przyjmują wartości 0 lub 1.\n",
        "\n",
        "Jak nie to musimy jes troszkę przerobić."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5ccOFNQkdBZ1",
        "outputId": "d73ae449-eaec-45e2-d004-cdbe57ebebcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape: (999, 8) y.shape: (999,)\n"
          ]
        }
      ],
      "source": [
        "X = data.drop(['income'], axis=1)\n",
        "y = data['income'].values\n",
        "np.unique(y)\n",
        "y[ y == ' <=50K'] = 0\n",
        "y[ y == ' >50K'] = 1\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "print(\"X.shape: {} y.shape: {}\".format(X.shape, y.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8clBAyZYdBZ2"
      },
      "source": [
        "Podzielmy zbiór na train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6nQPwvTsdBZ3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJe9IoasdBZ4"
      },
      "source": [
        "Teraz zbudujmy nasze **pipeline** preprocessingu. \n",
        "\n",
        "Wykorzystamy DataframeSelector aby wybrać określone atrybuty z DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1o71gSf1dBZ6"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# A class to select numerical or categorical columns \n",
        "# since Scikit-Learn doesn't handle DataFrames yet\n",
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, attribute_names):\n",
        "        self.attribute_names = attribute_names\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[self.attribute_names]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVwl8WbCdBZ7"
      },
      "source": [
        "Zbudujmy **pipeline** dla atrybutów numerycznych:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-8uEptoVdBZ9"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        (\"select_numeric\", DataFrameSelector([\"education-num\"])),\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ObkkKIxpdBZ9",
        "outputId": "71c1a75e-7092-4e83-a182-c1181be7c9d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10.],\n",
              "       [10.],\n",
              "       [12.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [14.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [12.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 2.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [12.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 6.],\n",
              "       [13.],\n",
              "       [ 7.],\n",
              "       [14.],\n",
              "       [11.],\n",
              "       [12.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [13.],\n",
              "       [ 7.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 2.],\n",
              "       [ 7.],\n",
              "       [14.],\n",
              "       [ 6.],\n",
              "       [10.],\n",
              "       [ 5.],\n",
              "       [13.],\n",
              "       [11.],\n",
              "       [12.],\n",
              "       [10.],\n",
              "       [ 7.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 7.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [14.],\n",
              "       [ 5.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [15.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [11.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [14.],\n",
              "       [14.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [ 6.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 8.],\n",
              "       [ 7.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 7.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 3.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 1.],\n",
              "       [ 8.],\n",
              "       [ 9.],\n",
              "       [12.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [14.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [ 3.],\n",
              "       [ 8.],\n",
              "       [11.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 7.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [12.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [ 5.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 2.],\n",
              "       [13.],\n",
              "       [ 6.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 6.],\n",
              "       [11.],\n",
              "       [ 3.],\n",
              "       [ 9.],\n",
              "       [16.],\n",
              "       [ 7.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [15.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [11.],\n",
              "       [11.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [14.],\n",
              "       [15.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [12.],\n",
              "       [ 4.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [11.],\n",
              "       [ 1.],\n",
              "       [ 9.],\n",
              "       [ 6.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [12.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 5.],\n",
              "       [ 9.],\n",
              "       [16.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 5.],\n",
              "       [ 7.],\n",
              "       [16.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [11.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [14.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [12.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 7.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [15.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 7.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 4.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 8.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [11.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [11.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [11.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 5.],\n",
              "       [14.],\n",
              "       [ 7.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [12.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [16.],\n",
              "       [14.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [12.],\n",
              "       [11.],\n",
              "       [11.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 6.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 7.],\n",
              "       [14.],\n",
              "       [ 7.],\n",
              "       [ 5.],\n",
              "       [ 5.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [14.],\n",
              "       [11.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [16.],\n",
              "       [ 9.],\n",
              "       [11.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [12.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 4.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [ 7.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 8.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [11.],\n",
              "       [11.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 4.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 6.],\n",
              "       [10.],\n",
              "       [11.],\n",
              "       [10.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [16.],\n",
              "       [11.],\n",
              "       [ 3.],\n",
              "       [16.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [11.],\n",
              "       [ 7.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [15.],\n",
              "       [ 9.],\n",
              "       [11.],\n",
              "       [ 6.],\n",
              "       [11.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 7.],\n",
              "       [11.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 4.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [12.],\n",
              "       [16.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [ 5.],\n",
              "       [ 7.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 8.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [11.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [ 7.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 3.],\n",
              "       [ 8.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [11.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 6.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [14.],\n",
              "       [14.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 2.],\n",
              "       [ 3.],\n",
              "       [ 6.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [12.],\n",
              "       [ 3.],\n",
              "       [11.],\n",
              "       [13.],\n",
              "       [14.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 6.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [11.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 3.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [ 9.],\n",
              "       [12.],\n",
              "       [10.],\n",
              "       [15.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 2.],\n",
              "       [13.],\n",
              "       [ 5.],\n",
              "       [ 4.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 6.],\n",
              "       [ 9.],\n",
              "       [12.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 6.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 2.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [16.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [16.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [11.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [11.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [16.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [11.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 7.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [ 5.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [11.],\n",
              "       [ 9.],\n",
              "       [ 4.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [12.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [16.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 4.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [ 6.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [11.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [11.],\n",
              "       [ 9.],\n",
              "       [ 6.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [15.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [ 7.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [11.],\n",
              "       [12.],\n",
              "       [10.],\n",
              "       [12.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [14.],\n",
              "       [12.],\n",
              "       [11.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 4.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 5.],\n",
              "       [ 9.],\n",
              "       [ 3.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 7.],\n",
              "       [10.],\n",
              "       [ 5.],\n",
              "       [10.],\n",
              "       [12.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [14.],\n",
              "       [10.],\n",
              "       [12.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [10.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [14.],\n",
              "       [14.],\n",
              "       [ 9.],\n",
              "       [ 5.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [10.],\n",
              "       [13.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [13.],\n",
              "       [13.],\n",
              "       [ 7.],\n",
              "       [ 5.],\n",
              "       [ 9.],\n",
              "       [ 9.],\n",
              "       [10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "num_pipeline.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG7eToMldBZ-"
      },
      "source": [
        "Będziemy także potrzebować imputera do kategorycznych kolumn napisowych (zwykły Imputer nie działa na tych kolumnach):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LLn-hG3IdBZ_"
      },
      "outputs": [],
      "source": [
        "# Inspired from stackoverflow.com/questions/25239958\n",
        "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
        "                                        index=X.columns)\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        return X.fillna(self.most_frequent_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11iwHMIZdBaA"
      },
      "source": [
        "Teraz możemy zbudować pipeline dla atrybutów kategorycznych.\n",
        "\n",
        "We can convert each categorical value to a one-hot vector using a OneHotEncoder. Right now this class can only handle integer categorical inputs, but in Scikit-Learn 0.20 it will also handle string categorical inputs (see PR https://github.com/scikit-learn/scikit-learn/issues/10521). So for now we import it from future_encoders.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3qprcQJQdBaC"
      },
      "outputs": [],
      "source": [
        "# from future_encoders import OneHotEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "        (\"select_cat\", DataFrameSelector([\"workclass\", \"education\", \"occupation\", \"gender\"])),\n",
        "        (\"imputer\", MostFrequentImputer()),\n",
        "        (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown = 'ignore')),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ck-RQWA3dBaD",
        "outputId": "436ca8d1-0566-4e9e-89de-53886acccd53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 1.],\n",
              "       [1., 0., 0., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 1.],\n",
              "       [0., 1., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "cat_pipeline.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzOM0tAAdBaE"
      },
      "source": [
        "Na koniec połączmy powyższe podejścia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ktdl5fwgdBaF"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
        "        (\"num_pipeline\", num_pipeline),\n",
        "        (\"cat_pipeline\", cat_pipeline),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALnZuUR-dBaG"
      },
      "source": [
        "# Zad\n",
        "\n",
        "Robimy StratifiedKFold i znajdujemy optymalne parametry dla\n",
        "\n",
        "* SVM z jądrem rbf\n",
        "* SVM z jądrem poly\n",
        "* SVM liniowego\n",
        "* Regresji logistycznej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7nCk3pOudBaH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "seed=123\n",
        "kfold = StratifiedKFold(n_splits=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fuE7T9TOdBaH",
        "outputId": "604eb429-f915-4429-c4d3-63e7537e5526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier__C': 10000.0, 'classifier__gamma': 0.001}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "pipe = Pipeline([\n",
        "    ('preprocessing', preprocess_pipeline), \n",
        "    ('classifier', SVC(kernel='rbf'))])\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "            'classifier__gamma': [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3],\n",
        "            'classifier__C': [1, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
        "}\n",
        "\n",
        "grid_1 = GridSearchCV(pipe, param_grid, cv=kfold)\n",
        "\n",
        "grid_1.fit(X_train, y_train)\n",
        "grid_1.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xiZNIE5LdBaI",
        "outputId": "0bc5f1b5-64d7-4df7-97c7-b79b35cd19cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier__C': 10.0, 'classifier__degree': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "pipe = Pipeline([\n",
        "    ('preprocessing', preprocess_pipeline), \n",
        "    ('classifier', SVC(kernel='poly'))])\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "            'classifier__degree': [1, 2, 3, 4, 5, 6],\n",
        "            'classifier__C': [1, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
        "}\n",
        "\n",
        "grid_2 = GridSearchCV(pipe, param_grid, cv=kfold)\n",
        "\n",
        "grid_2.fit(X_train, y_train)\n",
        "grid_2.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KBfvVa1DdBaI",
        "outputId": "9970c76d-0fb0-4a04-9ca5-67f253311164",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier__C': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "pipe = Pipeline([\n",
        "    ('preprocessing', preprocess_pipeline), \n",
        "    ('classifier', SVC(kernel='linear'))])\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "            'classifier__C': [1, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
        "}\n",
        "\n",
        "grid_3 = GridSearchCV(pipe, param_grid, cv=kfold)\n",
        "\n",
        "grid_3.fit(X_train, y_train)\n",
        "grid_3.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('preprocessing', preprocess_pipeline), \n",
        "    ('classifier', LogisticRegression())])\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "            'classifier__penalty': [\"l1\",\"l2\"],\n",
        "            'classifier__C': [1, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
        "}\n",
        "\n",
        "grid_4 = GridSearchCV(pipe, param_grid, cv=kfold)\n",
        "\n",
        "grid_4.fit(X_train, y_train)\n",
        "grid_4.best_params_"
      ],
      "metadata": {
        "id": "xDL_NLO5d7lS",
        "outputId": "006ddd51-20b3-42b5-c09c-902c4d9bf991",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "30 fits failed out of a total of 60.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.80721698        nan 0.79470912        nan 0.79345912\n",
            "        nan 0.79470912        nan 0.79220912        nan 0.79470912]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier__C': 1, 'classifier__penalty': 'l2'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FMJHgnQddBaI",
        "outputId": "7436b190-4884-4436-f771-cc0ccfc14933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM rbf\n",
            "precision_score: 0.75\n",
            "recall_score: 0.2608695652173913\n",
            "f1_score: 0.3870967741935483\n",
            "accuracy_score: 0.81\n",
            "SVM poly\n",
            "precision_score: 0.7333333333333333\n",
            "recall_score: 0.2391304347826087\n",
            "f1_score: 0.36065573770491804\n",
            "accuracy_score: 0.805\n",
            "SVM linear\n",
            "precision_score: 0.75\n",
            "recall_score: 0.1956521739130435\n",
            "f1_score: 0.3103448275862069\n",
            "accuracy_score: 0.8\n",
            "Logistic Regression\n",
            "precision_score: 0.7142857142857143\n",
            "recall_score: 0.32608695652173914\n",
            "f1_score: 0.4477611940298507\n",
            "accuracy_score: 0.815\n"
          ]
        }
      ],
      "source": [
        "from sklearn import  metrics\n",
        "\n",
        "\n",
        "models = []\n",
        "models.append(('SVM rbf', grid_1.best_estimator_))\n",
        "models.append(('SVM poly',grid_2.best_estimator_))\n",
        "models.append(('SVM linear', grid_3.best_estimator_))\n",
        "models.append(('Logistic Regression', grid_4.best_estimator_))\n",
        "\n",
        "\n",
        "precision_score = []\n",
        "recall_score = []\n",
        "f1_score = []\n",
        "accuracy_score = []\n",
        "for name, model in models:\n",
        "    print(name)\n",
        "    print(\"precision_score: {}\".format(metrics.precision_score(y_test, model.predict(X_test)) ))\n",
        "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test)) ))\n",
        "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test)) ))\n",
        "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
        "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test)))\n",
        "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test)))\n",
        "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test)))\n",
        "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GoAdNVoodBaJ",
        "outputId": "503df431-f6b9-4405-b213-f31970c406f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Method  precision_score  recall_score  f1_score  \\\n",
              "0              SVM rbf         0.750000      0.260870  0.387097   \n",
              "1             SVM poly         0.733333      0.239130  0.360656   \n",
              "2           SVM linear         0.750000      0.195652  0.310345   \n",
              "3  Logistic Regression         0.714286      0.326087  0.447761   \n",
              "\n",
              "   accuracy_score  \n",
              "0           0.810  \n",
              "1           0.805  \n",
              "2           0.800  \n",
              "3           0.815  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0823738b-9152-4a7b-9c15-326cea256fff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>precision_score</th>\n",
              "      <th>recall_score</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>accuracy_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVM rbf</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.387097</td>\n",
              "      <td>0.810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM poly</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.239130</td>\n",
              "      <td>0.360656</td>\n",
              "      <td>0.805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVM linear</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.195652</td>\n",
              "      <td>0.310345</td>\n",
              "      <td>0.800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.447761</td>\n",
              "      <td>0.815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0823738b-9152-4a7b-9c15-326cea256fff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0823738b-9152-4a7b-9c15-326cea256fff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0823738b-9152-4a7b-9c15-326cea256fff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import pandas as pd\n",
        "d = {'precision_score': precision_score, \n",
        "     'recall_score': recall_score, \n",
        "     'f1_score': f1_score,\n",
        "     'accuracy_score' : accuracy_score\n",
        "    }\n",
        "df = pd.DataFrame(data=d)\n",
        "df.insert(loc=0, column='Method', value=['SVM rbf', 'SVM poly', 'SVM linear', 'Logistic Regression'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDC7d-EEdBaL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "it_VoPHndBaM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENfZEpiqdBaM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Z09_F_categorical_data.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}